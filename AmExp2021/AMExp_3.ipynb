{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "AMExp-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "circular-cambodia"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
        "import optuna"
      ],
      "id": "circular-cambodia",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "modern-wellington"
      },
      "source": [
        "dft = pd.read_csv(\"train.csv\")\n",
        "tdf = pd.read_csv(\"test.csv\")"
      ],
      "id": "modern-wellington",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sitting-abuse"
      },
      "source": [
        "print(dft.info())\n",
        "print(\"--------\")\n",
        "print(tdf.info())"
      ],
      "id": "sitting-abuse",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "operational-procedure"
      },
      "source": [
        "def check_null(df):\n",
        "    for col in df.columns:\n",
        "        print(f\"{col}: {sum(dft[col].isna())}\")\n",
        "check_null(dft)\n",
        "print(\"---------\")\n",
        "check_null(tdf)"
      ],
      "id": "operational-procedure",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blond-chicken"
      },
      "source": [
        "print(dft.nunique())\n",
        "print(\"-------\")\n",
        "print(tdf.nunique())"
      ],
      "id": "blond-chicken",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "homeless-acquisition"
      },
      "source": [
        "cat_cols = ['Gender', 'City_Category', 'Customer_Category']\n",
        "\n",
        "dfu = dft.drop(columns=['Product_Holding_B1', 'Product_Holding_B2', 'Customer_ID'])\n",
        "dfu = pd.get_dummies(dfu, columns=cat_cols, prefix=cat_cols).astype(np.float32)\n",
        "\n",
        "tdu = tdf.drop(columns=['Product_Holding_B1', 'Customer_ID'])\n",
        "tdu = pd.get_dummies(tdu, columns=cat_cols, prefix=cat_cols).astype(np.float32)"
      ],
      "id": "homeless-acquisition",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "selective-amazon"
      },
      "source": [
        "from ast import literal_eval as le\n",
        "def interact(ser):\n",
        "    nop = 22\n",
        "    nou = ser.shape[0]\n",
        "    int_arr = np.zeros((nou, nop), dtype=np.float32)\n",
        "    for i in range(nou):\n",
        "        lst = le(ser[i])\n",
        "        for prod in lst:\n",
        "            idx = int(prod[1:])\n",
        "            int_arr[i][idx] = 1\n",
        "    \n",
        "    print(int_arr.shape)\n",
        "    return int_arr\n",
        "\n",
        "\n",
        "dfi = interact(dft['Product_Holding_B1'])\n",
        "dfr = interact(dft['Product_Holding_B2'])\n",
        "tdi = interact(tdf['Product_Holding_B1'])"
      ],
      "id": "selective-amazon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motivated-harris"
      },
      "source": [
        "# check for any issues through shapes\n",
        "\n",
        "assert dfi.shape[0]==dfu.shape[0]\n",
        "assert dfi.shape[1]==22\n",
        "assert dfr.shape[0]==dfu.shape[0]\n",
        "assert dfr.shape[1]==22\n",
        "assert tdi.shape[0]==tdf.shape[0]\n",
        "assert tdi.shape[1]==22\n",
        "assert dfu.shape[1]==10\n",
        "assert tdu.shape[1]==10"
      ],
      "id": "motivated-harris",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coordinate-denver"
      },
      "source": [
        "# prep train data\n",
        "\n",
        "X = np.concatenate((dfu.to_numpy(dtype=np.float32), dfi), axis=1)\n",
        "Y = dfi + dfr\n",
        "assert X.shape[0]==Y.shape[0]\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "id": "coordinate-denver",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "earlier-origin"
      },
      "source": [
        "---\n",
        "### Modelling"
      ],
      "id": "earlier-origin"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bridal-sphere"
      },
      "source": [
        "def get_model(trial, n_inputs, n_outputs):\n",
        "    model = Sequential()\n",
        "    n_layers = trial.suggest_int('nlayers', 1, 6)\n",
        "    num_hidden = trial.suggest_int('n_didden__input', 10, 129, step=2)\n",
        "    model.add(Dense(num_hidden, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        "    \n",
        "    for layer_i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int(f'n_hidden_{layer_i}', 10, 129, step=2)\n",
        "        model.add(Dense(num_hidden, activation='relu'))\n",
        "        drop = trial.suggest_float(f'drop_{layer_i}', 0, 0.6)\n",
        "        model.add(Dropout(drop))\n",
        "    \n",
        "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
        "    \n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    optim = keras.optimizers.Adam(learning_rate=lr)\n",
        "    prec = keras.metrics.Precision()\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=[prec])\n",
        "    \n",
        "    return model"
      ],
      "id": "bridal-sphere",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mechanical-casting"
      },
      "source": [
        "def objective(trial):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
        "    \n",
        "    model = get_model(trial, X.shape[1], Y.shape[1])\n",
        "    n_epochs = trial.suggest_int('n_epochs', 10, 50)\n",
        "    bs = trial.suggest_categorical('batch_size', [16, 32])\n",
        "    vs = trial.suggest_categorical('split_size', [0.2, 0.3])\n",
        "    model.fit(X, Y, batch_size=bs, epochs=n_epochs, validation_split=vs, verbose=1, workers=4)\n",
        "    \n",
        "    scores = model.evaluate(x_test, y_test, batch_size=16, workers=4)\n",
        "    return scores[1]"
      ],
      "id": "mechanical-casting",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "statutory-production"
      },
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20, n_jobs=-1)"
      ],
      "id": "statutory-production",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctgu5d0KeHYX"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "id": "ctgu5d0KeHYX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9HJ0mq08k1Q"
      },
      "source": [
        "optuna.visualization.plot_slice(study)"
      ],
      "id": "j9HJ0mq08k1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcSNidTO8nlG"
      },
      "source": [
        "print(study.best_trials)\n",
        "print(\"----------\")\n",
        "print(study.best_value)\n",
        "print(\"----------\")\n",
        "print(study.best_params)\n",
        "print(\"----------\")"
      ],
      "id": "YcSNidTO8nlG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXAhKaOQVHbK"
      },
      "source": [
        "# creating optimized model\n",
        "n_inputs = X.shape[1]\n",
        "n_outputs = Y.shape[1]\n",
        "op_model = Sequential()\n",
        "op_model.add(Dense(64, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        "op_model.add(Dense(48, activation='relu'))\n",
        "op_model.add(Dropout(0.4))\n",
        "op_model.add(Dense(16, activation='relu'))\n",
        "op_model.add(Dropout(0.2))\n",
        "    \n",
        "op_model.add(Dense(n_outputs, activation='sigmoid'))\n",
        "    \n",
        "lr = 0.0003\n",
        "optim = keras.optimizers.Adam(learning_rate=lr)\n",
        "prec = keras.metrics.Precision()\n",
        "op_model.compile(loss='binary_crossentropy', optimizer=optim, metrics=[prec])"
      ],
      "id": "JXAhKaOQVHbK",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OPcCLpHWfqA"
      },
      "source": [
        "n_epochs = 50\n",
        "bs = 16\n",
        "vs = 0.2\n",
        "op_model.fit(X, Y, batch_size=bs, epochs=n_epochs, validation_split=vs, verbose=1, workers=4)"
      ],
      "id": "5OPcCLpHWfqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ17_wQEWt3W"
      },
      "source": [
        "# Generating predictions\n",
        "\n",
        "xt = np.concatenate((tdu.to_numpy(dtype=np.float32), tdi), axis=1)\n",
        "yt = op_model.predict(xt, batch_size=16)\n",
        "print(yt.shape)"
      ],
      "id": "CQ17_wQEWt3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDxEe-oAXazz"
      },
      "source": [
        "req_pred = yt - (yt*tdi)\n",
        "req_pred"
      ],
      "id": "LDxEe-oAXazz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UFss6RUX7gC"
      },
      "source": [
        "# Generating submissions\n",
        "sub = pd.read_csv(\"submission.csv\")\n",
        "preds = []\n",
        "for i in range(req_pred.shape[0]):\n",
        "  ind = np.argpartition(req_pred[i], -3)[-3:]\n",
        "  temp = []\n",
        "  for idx in range(3):\n",
        "    st = 'P00' if ind[idx]==0 else f'P{ind[idx]}'\n",
        "    temp.append(st)\n",
        "  preds.append(temp)"
      ],
      "id": "-UFss6RUX7gC",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcTxv2Xg8se"
      },
      "source": [
        "sub"
      ],
      "id": "ONcTxv2Xg8se",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQGdby5KhFAu"
      },
      "source": [
        "preds"
      ],
      "id": "zQGdby5KhFAu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPMdTScRb1SD"
      },
      "source": [
        "sub['Product_Holding_B2'] = preds\n",
        "sub"
      ],
      "id": "xPMdTScRb1SD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG2JxEOPb7Pj"
      },
      "source": [
        "sub.to_csv('sub.csv', index=False)"
      ],
      "id": "NG2JxEOPb7Pj",
      "execution_count": 35,
      "outputs": []
    }
  ]
}